{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spliting the images/images path into train,test and validation , as the dataset in not provided in that format","metadata":{"papermill":{"duration":0.005309,"end_time":"2023-03-11T16:07:23.148688","exception":false,"start_time":"2023-03-11T16:07:23.143379","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Define data path\ndata_dir = '/kaggle/input/bengali-food-58/ALLFOOD'\n\n# Get list of image files and labels\nimage_files = []\nlabels = []\nfor class_label in os.listdir(data_dir):\n    class_dir = os.path.join(data_dir, class_label)\n    for image_file in os.listdir(class_dir):\n        image_files.append(os.path.join(class_dir, image_file))\n        labels.append(class_label)\n\n# Split data into training and testing sets\ntrain_files, test_files, train_labels, test_labels = train_test_split(image_files, labels, test_size=0.1)\n\n# Split training set into training and validation sets\ntrain_files, valid_files, train_labels, valid_labels = train_test_split(train_files, train_labels, test_size=0.1)\n\n# Create dataframes for the splits\ntrain_df = pd.DataFrame({'filename': train_files, 'class': train_labels})\nvalid_df = pd.DataFrame({'filename': valid_files, 'class': valid_labels})\ntest_df = pd.DataFrame({'filename': test_files, 'class': test_labels})\n\n","metadata":{"papermill":{"duration":26.270513,"end_time":"2023-03-11T16:07:49.423322","exception":false,"start_time":"2023-03-11T16:07:23.152809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-24T20:23:40.302014Z","iopub.execute_input":"2023-06-24T20:23:40.302812Z","iopub.status.idle":"2023-06-24T20:23:43.788596Z","shell.execute_reply.started":"2023-06-24T20:23:40.302777Z","shell.execute_reply":"2023-06-24T20:23:43.787552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{"papermill":{"duration":0.002836,"end_time":"2023-03-11T16:07:49.429634","exception":false,"start_time":"2023-03-11T16:07:49.426798","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\n%matplotlib inline\nimport numpy as np\nfrom collections import defaultdict\nimport collections\nimport os\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,Conv2D\nfrom tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.optimizers import SGD,Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.metrics import classification_report","metadata":{"papermill":{"duration":5.867775,"end_time":"2023-03-11T16:07:55.300213","exception":false,"start_time":"2023-03-11T16:07:49.432438","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-24T20:23:43.790909Z","iopub.execute_input":"2023-06-24T20:23:43.791528Z","iopub.status.idle":"2023-06-24T20:23:51.650074Z","shell.execute_reply.started":"2023-06-24T20:23:43.791495Z","shell.execute_reply":"2023-06-24T20:23:51.649121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Definind different parameters and data augmentation . Loading the datasets  using image-data generator ","metadata":{"papermill":{"duration":0.002836,"end_time":"2023-03-11T16:07:55.306116","exception":false,"start_time":"2023-03-11T16:07:55.303280","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\nimg_height = 224\nimg_width = 224\nn_classes = 58\n\nbatch_size = 64\n\n# train_datagen = ImageDataGenerator(\n#     rescale=1. / 255,\n#     rotation_range=20\n   \n    \n# )\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.3,\n    zoom_range=0.4,\n    rotation_range=30,\n    vertical_flip=True,\n    horizontal_flip=True,\n    width_shift_range=0.4,\n    height_shift_range=0.3,\n    brightness_range=[0.8, 1.2],\n    channel_shift_range=20,\n    fill_mode='nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1. / 255)\n\n# Generate training set from dataframe\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True)\n\n# Generate validation set from dataframe\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    valid_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False)\n\n# Generate testing set from dataframe\ntest_generator = validation_datagen.flow_from_dataframe(\n    test_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False)\n\n\n","metadata":{"papermill":{"duration":49.976077,"end_time":"2023-03-11T16:08:45.285100","exception":false,"start_time":"2023-03-11T16:07:55.309023","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-24T20:23:51.651610Z","iopub.execute_input":"2023-06-24T20:23:51.652357Z","iopub.status.idle":"2023-06-24T20:23:55.238829Z","shell.execute_reply.started":"2023-06-24T20:23:51.652322Z","shell.execute_reply":"2023-06-24T20:23:55.237752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the pre-trained res-net model from keras and freezing first 500 layers . We have decided to re-train the last few layers according to our dataset as the contain the most complex features .","metadata":{"papermill":{"duration":0.002851,"end_time":"2023-03-11T16:08:45.291101","exception":false,"start_time":"2023-03-11T16:08:45.288250","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inception V3 311 layers\ndensenet = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False,input_shape=(img_width,img_width,3))\nfor layer in densenet.layers[:500]:\n    layer.trainable=False","metadata":{"papermill":{"duration":14.843539,"end_time":"2023-03-11T16:09:00.137499","exception":false,"start_time":"2023-03-11T16:08:45.293960","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-24T20:25:19.273562Z","iopub.execute_input":"2023-06-24T20:25:19.273976Z","iopub.status.idle":"2023-06-24T20:25:26.285250Z","shell.execute_reply.started":"2023-06-24T20:25:19.273946Z","shell.execute_reply":"2023-06-24T20:25:26.284260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c=0\nfor layer in densenet.layers:\n    c+=1\nc","metadata":{"execution":{"iopub.status.busy":"2023-06-24T20:25:28.002843Z","iopub.execute_input":"2023-06-24T20:25:28.003215Z","iopub.status.idle":"2023-06-24T20:25:28.012957Z","shell.execute_reply.started":"2023-06-24T20:25:28.003187Z","shell.execute_reply":"2023-06-24T20:25:28.011964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n# Get the class labels from the generator\nclass_labels = train_generator.classes\n\n# Compute class weights\nclass_weights = compute_class_weight('balanced',classes= np.unique(class_labels),y= class_labels)\n\n# Convert class weights to a dictionary\n# class_indices = train_generator.class_indices\n# class_weights_dict = dict(zip(class_indices.values(), class_weights))\nclass_weights_dict = dict(zip(np.unique(class_labels), class_weights))","metadata":{"execution":{"iopub.status.busy":"2023-06-24T20:25:39.665321Z","iopub.execute_input":"2023-06-24T20:25:39.665798Z","iopub.status.idle":"2023-06-24T20:25:39.679574Z","shell.execute_reply.started":"2023-06-24T20:25:39.665756Z","shell.execute_reply":"2023-06-24T20:25:39.678513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training ","metadata":{"papermill":{"duration":0.009497,"end_time":"2023-03-11T16:09:00.157402","exception":false,"start_time":"2023-03-11T16:09:00.147905","status":"completed"},"tags":[]}},{"cell_type":"code","source":"x = densenet.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(150,activation='relu')(x)\nx = Dropout(0.2)(x)\noutput = Dense(n_classes,kernel_regularizer=regularizers.l2(0.01), activation='softmax')(x)\nmodel = Model(inputs=densenet.input, outputs=output)\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='./densenet_best_loss.hdf5', verbose=1, save_best_only=True)\nfrom keras.callbacks import LearningRateScheduler\ndef learning_rate_scheduler(epoch, lr):\n    initial_lr=0.0001\n    warmup_epochs = 10 # Number of epochs for warm-up\n    if epoch < warmup_epochs:\n        # Gradually increase the learning rate\n        warmup_factor = epoch / warmup_epochs\n        lr = warmup_factor*initial_lr\n        return lr\n    else:\n        return initial_lr\n\n\nlr_scheduler = LearningRateScheduler(learning_rate_scheduler)\nhistory=model.fit(train_generator,\n        steps_per_epoch = len(train_generator) ,\n        validation_data = validation_generator,\n        validation_steps = len(validation_generator),\n        epochs=60,\n        verbose=1,\n       callbacks=[ lr_scheduler,checkpointer],\n         class_weight=class_weights_dict)\n         \nmodel.save('./densenet_best_Final.hdf5')","metadata":{"papermill":{"duration":30374.040769,"end_time":"2023-03-12T00:35:14.207974","exception":false,"start_time":"2023-03-11T16:09:00.167205","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-24T20:25:43.481691Z","iopub.execute_input":"2023-06-24T20:25:43.482147Z","iopub.status.idle":"2023-06-24T20:29:45.692580Z","shell.execute_reply.started":"2023-06-24T20:25:43.482116Z","shell.execute_reply":"2023-06-24T20:29:45.691534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\nimport matplotlib.pyplot as plt\n\nepochs = range(1, len(train_loss) + 1)\n\n\nimport pandas as pd\n\nloss_df = pd.DataFrame({'Epoch': epochs, 'Train Loss': train_loss, 'Validation Loss': val_loss})\nloss_df.to_csv('inception_loss_data.csv', index=False)\n\n\n\n\n\nplt.plot(epochs, train_loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Result","metadata":{"papermill":{"duration":0.789023,"end_time":"2023-03-12T00:35:15.678339","exception":false,"start_time":"2023-03-12T00:35:14.889316","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# y_pred = model.predict(test_generator)\n# y_pred = tf.argmax(y_pred, axis=1)\n# print('Classification Report:')\n# print(classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()))","metadata":{"papermill":{"duration":249.959648,"end_time":"2023-03-12T00:39:26.323213","exception":false,"start_time":"2023-03-12T00:35:16.363565","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-24T20:24:04.998069Z","iopub.status.idle":"2023-06-24T20:24:04.999038Z","shell.execute_reply.started":"2023-06-24T20:24:04.998774Z","shell.execute_reply":"2023-06-24T20:24:04.998799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_generator)\ny_pred = tf.argmax(y_pred, axis=1)\nclass_labels = list(test_generator.class_indices.keys())\nprint('Classification Report:')\nprint(classification_report(test_generator.classes, y_pred, labels=range(len(class_labels)), target_names=class_labels))","metadata":{"execution":{"iopub.status.busy":"2023-06-24T20:30:51.869556Z","iopub.execute_input":"2023-06-24T20:30:51.870025Z","iopub.status.idle":"2023-06-24T20:31:12.330263Z","shell.execute_reply.started":"2023-06-24T20:30:51.869989Z","shell.execute_reply":"2023-06-24T20:31:12.329296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef switch_key_value_positions(class_indices):\n    switched_indices = {v: k for k, v in class_indices.items()}\n    return switched_indices\n\n# Example usage\nclass_indices = test_generator.class_indices  # Assuming `test_generator` is your generator object\n\nswitched_indices = switch_key_value_positions(class_indices)\n\n# Convert the switched indices to JSON format\njson_data = json.dumps(switched_indices)\n\n# Save the JSON data to a file\nwith open('/kaggle/working/densenet_indices.json', 'w') as file:\n    file.write(json_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-24T20:31:12.332525Z","iopub.execute_input":"2023-06-24T20:31:12.333280Z","iopub.status.idle":"2023-06-24T20:31:12.341157Z","shell.execute_reply.started":"2023-06-24T20:31:12.333243Z","shell.execute_reply":"2023-06-24T20:31:12.340043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n\n# Load the model from HDF5 file\nmodel = load_model('/kaggle/working/densenet_best_loss.hdf5')\ny_pred = model.predict(test_generator)\ny_pred = tf.argmax(y_pred, axis=1)\nclass_labels = list(test_generator.class_indices.keys())\nprint('Classification Report:')\nprint(classification_report(test_generator.classes, y_pred, labels=range(len(class_labels)), target_names=class_labels))","metadata":{"execution":{"iopub.status.busy":"2023-06-24T20:31:12.342786Z","iopub.execute_input":"2023-06-24T20:31:12.343234Z","iopub.status.idle":"2023-06-24T20:31:29.395818Z","shell.execute_reply.started":"2023-06-24T20:31:12.343204Z","shell.execute_reply":"2023-06-24T20:31:29.394764Z"},"trusted":true},"execution_count":null,"outputs":[]}]}