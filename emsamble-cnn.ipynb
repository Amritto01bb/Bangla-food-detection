{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n%matplotlib inline\nimport numpy as np\nfrom collections import defaultdict\nimport collections\nimport os\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,Conv2D\nfrom tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.optimizers import SGD,Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.metrics import classification_report\n\n# Define data path\ndata_dir = '/kaggle/input/bengali-food-58/ALLFOOD'\n\n# Get list of image files and labels\nimage_files = []\nlabels = []\nfor class_label in os.listdir(data_dir):\n    class_dir = os.path.join(data_dir, class_label)\n    for image_file in os.listdir(class_dir):\n        image_files.append(os.path.join(class_dir, image_file))\n        labels.append(class_label)\n\n\n# Split data into training and testing sets\ntrain_files, test_files, train_labels, test_labels = train_test_split(image_files, labels, test_size=0.1)\n\n# Split training set into training and validation sets\ntrain_files, valid_files, train_labels, valid_labels = train_test_split(train_files, train_labels, test_size=0.1)\n\n# Create dataframes for the splits\ntrain_df = pd.DataFrame({'filename': train_files, 'class': train_labels})\nvalid_df = pd.DataFrame({'filename': valid_files, 'class': valid_labels})\ntest_df = pd.DataFrame({'filename': test_files, 'class': test_labels})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-05T17:02:08.172005Z","iopub.execute_input":"2023-08-05T17:02:08.172368Z","iopub.status.idle":"2023-08-05T17:02:10.228270Z","shell.execute_reply.started":"2023-08-05T17:02:08.172337Z","shell.execute_reply":"2023-08-05T17:02:10.227246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 224\nimg_width = 224\nn_classes = 58\n\nbatch_size = 64\n\n# train_datagen = ImageDataGenerator(\n#     rescale=1. / 255,\n#     rotation_range=20\n   \n    \n# )\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.3,\n    zoom_range=0.4,\n    rotation_range=30,\n    vertical_flip=True,\n    horizontal_flip=True,\n    width_shift_range=0.4,\n    height_shift_range=0.3,\n    brightness_range=[0.8, 1.2],\n    channel_shift_range=20,\n    fill_mode='nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1. / 255)\n\n# Generate training set from dataframe\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True)\n\n# Generate validation set from dataframe\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    valid_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False)\n\n# Generate testing set from dataframe\ntest_generator = validation_datagen.flow_from_dataframe(\n    test_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T17:02:21.014049Z","iopub.execute_input":"2023-08-05T17:02:21.014420Z","iopub.status.idle":"2023-08-05T17:02:25.022316Z","shell.execute_reply.started":"2023-08-05T17:02:21.014389Z","shell.execute_reply":"2023-08-05T17:02:25.021330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model,load_model\nfrom tensorflow.keras.layers import Input,Average\n\nmodel_1=load_model('/kaggle/input/models/Xception_best_loss.hdf5')\nmodel_1=Model(inputs=model_1.inputs,outputs=model_1.outputs,name='xception')\n\nmodel_2=load_model('/kaggle/input/models/densenet_best_loss.hdf5')\nmodel_2=Model(inputs=model_2.inputs,outputs=model_2.outputs,name='densenet')\n\n\nmodels=[model_1,model_2]\n\nmodel_input = Input(shape=(224,224,3))\nmodel_outputs = [model(model_input) for model in models]\n\nensemble_output = Average()(model_outputs)\n\nensemble_model=Model(inputs=model_input,outputs=ensemble_output,name='ensemble')\n\nensemble_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T17:53:52.136899Z","iopub.execute_input":"2023-08-05T17:53:52.137668Z","iopub.status.idle":"2023-08-05T17:54:03.112092Z","shell.execute_reply.started":"2023-08-05T17:53:52.137632Z","shell.execute_reply":"2023-08-05T17:54:03.111094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-05T17:54:03.114005Z","iopub.execute_input":"2023-08-05T17:54:03.114338Z","iopub.status.idle":"2023-08-05T17:54:03.194901Z","shell.execute_reply.started":"2023-08-05T17:54:03.114305Z","shell.execute_reply":"2023-08-05T17:54:03.193963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n# Get the class labels from the generator\nclass_labels = train_generator.classes\n\n# Compute class weights\nclass_weights = compute_class_weight('balanced',classes= np.unique(class_labels),y= class_labels)\n\n\nclass_weights_dict = dict(zip(np.unique(class_labels), class_weights))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T17:54:07.936276Z","iopub.execute_input":"2023-08-05T17:54:07.937047Z","iopub.status.idle":"2023-08-05T17:54:07.948154Z","shell.execute_reply.started":"2023-08-05T17:54:07.937007Z","shell.execute_reply":"2023-08-05T17:54:07.947144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\ndef learning_rate_scheduler(epoch, lr):\n    initial_lr=0.0001\n    warmup_epochs = 5 # Number of epochs for warm-up\n    if epoch < warmup_epochs:\n        # Gradually increase the learning rate\n        warmup_factor = epoch / warmup_epochs\n        lr = warmup_factor*initial_lr\n        return lr\n    else:\n        return initial_lr","metadata":{"execution":{"iopub.status.busy":"2023-08-05T17:54:17.551331Z","iopub.execute_input":"2023-08-05T17:54:17.551704Z","iopub.status.idle":"2023-08-05T17:54:17.558279Z","shell.execute_reply.started":"2023-08-05T17:54:17.551670Z","shell.execute_reply":"2023-08-05T17:54:17.557243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = LearningRateScheduler(learning_rate_scheduler)\nhistory=ensemble_model.fit(train_generator,\n        steps_per_epoch = len(train_generator) ,\n        validation_data = validation_generator,\n        validation_steps = len(validation_generator),\n        epochs=10,\n        verbose=1, \n        callbacks=[ lr_scheduler],\n         class_weight=class_weights_dict)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T17:55:02.587410Z","iopub.execute_input":"2023-08-05T17:55:02.588358Z","iopub.status.idle":"2023-08-05T18:25:45.858681Z","shell.execute_reply.started":"2023-08-05T17:55:02.588314Z","shell.execute_reply":"2023-08-05T18:25:45.857613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = ensemble_model.predict(test_generator)\ny_pred = tf.argmax(y_pred, axis=1)\nclass_labels = list(test_generator.class_indices.keys())\nprint('Classification Report:')\nprint(classification_report(test_generator.classes, y_pred, labels=range(len(class_labels)), target_names=class_labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T19:20:49.340637Z","iopub.execute_input":"2023-08-05T19:20:49.341049Z","iopub.status.idle":"2023-08-05T19:21:08.574969Z","shell.execute_reply.started":"2023-08-05T19:20:49.341015Z","shell.execute_reply":"2023-08-05T19:21:08.573183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Assuming you have created the ensemble model by loading two separate models\n\n# Save the weights of the ensemble model\nensemble_model.save_weights('ensemble_weights.h5')\n\n# Save the architecture of the ensemble model\nwith open('ensemble_architecture.json', 'w') as f:\n    f.write(ensemble_model.to_json())\n\n# Alternatively, you can use YAML format instead of JSON\n# with open('ensemble_architecture.yaml', 'w') as f:\n#     f.write(ensemble_model.to_yaml())\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T19:39:04.313322Z","iopub.execute_input":"2023-08-05T19:39:04.313708Z","iopub.status.idle":"2023-08-05T19:39:05.759545Z","shell.execute_reply.started":"2023-08-05T19:39:04.313674Z","shell.execute_reply":"2023-08-05T19:39:05.758527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import model_from_json\n\n# Load the architecture from JSON\nwith open('ensemble_architecture.json', 'r') as f:\n    ensemble_model_architecture = f.read()\n\n# Alternatively, if using YAML\n# with open('ensemble_architecture.yaml', 'r') as f:\n#     ensemble_model_architecture = f.read()\n\n# Create the ensemble model using the loaded architecture\nmodel = model_from_json(ensemble_model_architecture)\n\n# Load the weights into the ensemble model\nmodel.load_weights('ensemble_weights.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-05T19:40:57.266832Z","iopub.execute_input":"2023-08-05T19:40:57.267230Z","iopub.status.idle":"2023-08-05T19:41:06.337182Z","shell.execute_reply.started":"2023-08-05T19:40:57.267197Z","shell.execute_reply":"2023-08-05T19:41:06.336154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = pd.DataFrame({'filename': image_files, 'class': labels})","metadata":{"execution":{"iopub.status.busy":"2023-08-05T19:43:03.787845Z","iopub.execute_input":"2023-08-05T19:43:03.789031Z","iopub.status.idle":"2023-08-05T19:43:03.797542Z","shell.execute_reply.started":"2023-08-05T19:43:03.788980Z","shell.execute_reply":"2023-08-05T19:43:03.796500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_datagen = ImageDataGenerator(rescale=1. / 255)\ndata_generator = validation_datagen.flow_from_dataframe(\n    data_df,\n    x_col='filename',\n    y_col='class',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T19:44:38.319385Z","iopub.execute_input":"2023-08-05T19:44:38.319763Z","iopub.status.idle":"2023-08-05T19:44:50.073951Z","shell.execute_reply.started":"2023-08-05T19:44:38.319731Z","shell.execute_reply":"2023-08-05T19:44:50.072837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(data_generator)\ny_pred = tf.argmax(y_pred, axis=1)\nclass_labels = list(data_generator.class_indices.keys())\nprint('Classification Report:')\nprint(classification_report(data_generator.classes, y_pred, labels=range(len(class_labels)), target_names=class_labels))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T19:48:24.975302Z","iopub.execute_input":"2023-08-05T19:48:24.975693Z","iopub.status.idle":"2023-08-05T19:49:18.213397Z","shell.execute_reply.started":"2023-08-05T19:48:24.975658Z","shell.execute_reply":"2023-08-05T19:49:18.212313Z"},"trusted":true},"execution_count":null,"outputs":[]}]}